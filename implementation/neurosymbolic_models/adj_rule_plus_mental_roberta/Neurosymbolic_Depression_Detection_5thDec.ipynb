{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1sEslY6oD_BTi5VdZoNfGjLBdw1iNrmb0",
     "timestamp": 1733468976619
    },
    {
     "file_id": "1Ms3ZvuouiBFV5wctVyAY8Vfsknr3-U-n",
     "timestamp": 1732176466035
    }
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!wget https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
    "!apt install ./rclone-v1.50.1-linux-amd64.deb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDnam4upy6Tu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733473578690,
     "user_tz": 420,
     "elapsed": 16345,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "02b4a093-6106-4f71-d4bb-478c1b1bda54"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2024-12-06 08:26:02--  https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
      "Resolving downloads.rclone.org (downloads.rclone.org)... 95.217.6.16, 2a01:4f9:c012:7154::1\n",
      "Connecting to downloads.rclone.org (downloads.rclone.org)|95.217.6.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11917114 (11M) [application/vnd.debian.binary-package]\n",
      "Saving to: ‘rclone-v1.50.1-linux-amd64.deb’\n",
      "\n",
      "rclone-v1.50.1-linu 100%[===================>]  11.36M  5.39MB/s    in 2.1s    \n",
      "\n",
      "2024-12-06 08:26:05 (5.39 MB/s) - ‘rclone-v1.50.1-linux-amd64.deb’ saved [11917114/11917114]\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'rclone' instead of './rclone-v1.50.1-linux-amd64.deb'\n",
      "The following NEW packages will be installed:\n",
      "  rclone\n",
      "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
      "Need to get 0 B/11.9 MB of archives.\n",
      "After this operation, 36.1 MB of additional disk space will be used.\n",
      "Get:1 /content/rclone-v1.50.1-linux-amd64.deb rclone amd64 1.50.1 [11.9 MB]\n",
      "Selecting previously unselected package rclone.\n",
      "(Reading database ... 123632 files and directories currently installed.)\n",
      "Preparing to unpack .../rclone-v1.50.1-linux-amd64.deb ...\n",
      "Unpacking rclone (1.50.1) ...\n",
      "Setting up rclone (1.50.1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!rclone config"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goh0GUq7y72i",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733473666086,
     "user_tz": 420,
     "elapsed": 53230,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "8b6a045b-f34e-41a0-da45-ce22b9c0cedb"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2024/12/06 08:26:52 NOTICE: Config file \"/root/.config/rclone/rclone.conf\" not found - using defaults\n",
      "No remotes found - make a new one\n",
      "n) New remote\n",
      "s) Set configuration password\n",
      "q) Quit config\n",
      "n/s/q> n\n",
      "name> onedrive\n",
      "Type of storage to configure.\n",
      "Enter a string value. Press Enter for the default (\"\").\n",
      "Choose a number from below, or type in your own value\n",
      "\u001B[91m 1 / 1Fichier\n",
      "   \\ \"fichier\"\n",
      "\u001B[0m\u001B[92m 2 / Alias for an existing remote\n",
      "   \\ \"alias\"\n",
      "\u001B[0m\u001B[91m 3 / Amazon Drive\n",
      "   \\ \"amazon cloud drive\"\n",
      "\u001B[0m\u001B[92m 4 / Amazon S3 Compliant Storage Provider (AWS, Alibaba, Ceph, Digital Ocean, Dreamhost, IBM COS, Minio, etc)\n",
      "   \\ \"s3\"\n",
      "\u001B[0m\u001B[91m 5 / Backblaze B2\n",
      "   \\ \"b2\"\n",
      "\u001B[0m\u001B[92m 6 / Box\n",
      "   \\ \"box\"\n",
      "\u001B[0m\u001B[91m 7 / Cache a remote\n",
      "   \\ \"cache\"\n",
      "\u001B[0m\u001B[92m 8 / Citrix Sharefile\n",
      "   \\ \"sharefile\"\n",
      "\u001B[0m\u001B[91m 9 / Dropbox\n",
      "   \\ \"dropbox\"\n",
      "\u001B[0m\u001B[92m10 / Encrypt/Decrypt a remote\n",
      "   \\ \"crypt\"\n",
      "\u001B[0m\u001B[91m11 / FTP Connection\n",
      "   \\ \"ftp\"\n",
      "\u001B[0m\u001B[92m12 / Google Cloud Storage (this is not Google Drive)\n",
      "   \\ \"google cloud storage\"\n",
      "\u001B[0m\u001B[91m13 / Google Drive\n",
      "   \\ \"drive\"\n",
      "\u001B[0m\u001B[92m14 / Google Photos\n",
      "   \\ \"google photos\"\n",
      "\u001B[0m\u001B[91m15 / Hubic\n",
      "   \\ \"hubic\"\n",
      "\u001B[0m\u001B[92m16 / JottaCloud\n",
      "   \\ \"jottacloud\"\n",
      "\u001B[0m\u001B[91m17 / Koofr\n",
      "   \\ \"koofr\"\n",
      "\u001B[0m\u001B[92m18 / Local Disk\n",
      "   \\ \"local\"\n",
      "\u001B[0m\u001B[91m19 / Mail.ru Cloud\n",
      "   \\ \"mailru\"\n",
      "\u001B[0m\u001B[92m20 / Mega\n",
      "   \\ \"mega\"\n",
      "\u001B[0m\u001B[91m21 / Microsoft Azure Blob Storage\n",
      "   \\ \"azureblob\"\n",
      "\u001B[0m\u001B[92m22 / Microsoft OneDrive\n",
      "   \\ \"onedrive\"\n",
      "\u001B[0m\u001B[91m23 / OpenDrive\n",
      "   \\ \"opendrive\"\n",
      "\u001B[0m\u001B[92m24 / Openstack Swift (Rackspace Cloud Files, Memset Memstore, OVH)\n",
      "   \\ \"swift\"\n",
      "\u001B[0m\u001B[91m25 / Pcloud\n",
      "   \\ \"pcloud\"\n",
      "\u001B[0m\u001B[92m26 / Put.io\n",
      "   \\ \"putio\"\n",
      "\u001B[0m\u001B[91m27 / QingCloud Object Storage\n",
      "   \\ \"qingstor\"\n",
      "\u001B[0m\u001B[92m28 / SSH/SFTP Connection\n",
      "   \\ \"sftp\"\n",
      "\u001B[0m\u001B[91m29 / Transparently chunk/split large files\n",
      "   \\ \"chunker\"\n",
      "\u001B[0m\u001B[92m30 / Union merges the contents of several remotes\n",
      "   \\ \"union\"\n",
      "\u001B[0m\u001B[91m31 / Webdav\n",
      "   \\ \"webdav\"\n",
      "\u001B[0m\u001B[92m32 / Yandex Disk\n",
      "   \\ \"yandex\"\n",
      "\u001B[0m\u001B[91m33 / http Connection\n",
      "   \\ \"http\"\n",
      "\u001B[0m\u001B[92m34 / premiumize.me\n",
      "   \\ \"premiumizeme\"\n",
      "\u001B[0mStorage> 22\n",
      "** See help for onedrive backend at: https://rclone.org/onedrive/ **\n",
      "\n",
      "Microsoft App Client Id\n",
      "Leave blank normally.\n",
      "Enter a string value. Press Enter for the default (\"\").\n",
      "client_id> \n",
      "Microsoft App Client Secret\n",
      "Leave blank normally.\n",
      "Enter a string value. Press Enter for the default (\"\").\n",
      "client_secret> \n",
      "Edit advanced config? (y/n)\n",
      "y) Yes\n",
      "n) No\n",
      "y/n> n\n",
      "Remote config\n",
      "Use auto config?\n",
      " * Say Y if not sure\n",
      " * Say N if you are working on a remote or headless machine\n",
      "y) Yes\n",
      "n) No\n",
      "y/n> n\n",
      "For this to work, you will need rclone available on a machine that has a web browser available.\n",
      "Execute the following on your machine (same rclone version recommended) :\n",
      "\trclone authorize \"onedrive\"\n",
      "Then paste the result below:\n",
      "result> {\"access_token\":\"eyJ0eXAiOiJKV1QiLCJub25jZSI6ImJJN21TU2VJNW1vNmIwZXBpdVo3dGlDcWdYd2RfQ0xFc1lva2h0QXZBaUkiLCJhbGciOiJSUzI1NiIsIng1dCI6Inp4ZWcyV09OcFRrd041R21lWWN1VGR0QzZKMCIsImtpZCI6Inp4ZWcyV09OcFRrd041R21lWWN1VGR0QzZKMCJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTAwMDAtYzAwMC0wMDAwMDAwMDAwMDAiLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC8zZGVkOGIxYi0wNzBkLTQ2MjktODJlNC1jMGIwMTlmNDYwNTcvIiwiaWF0IjoxNzMzNDczMjM0LCJuYmYiOjE3MzM0NzMyMzQsImV4cCI6MTczMzQ3Nzc0OSwiYWNjdCI6MCwiYWNyIjoiMSIsImFjcnMiOlsidXJuOnVzZXI6cmVnaXN0ZXJzZWN1cml0eWluZm8iXSwiYWlvIjoiQVRRQXkvOFlBQUFBWnBWVkR6azNZUnF1VUxTYVJacjVzMXVOTnc4dTFxU0xDeUpNTDRhRW1Zd3dtZ2hOemxpd2tWVDN5N3gwUmV5bSIsImFtciI6WyJwd2QiXSwiYXBwX2Rpc3BsYXluYW1lIjoicmNsb25lIiwiYXBwaWQiOiJiMTU2NjVkOS1lZGE2LTQwOTItODUzOS0wZWVjMzc2YWZkNTkiLCJhcHBpZGFjciI6IjEiLCJmYW1pbHlfbmFtZSI6IktpbmkiLCJnaXZlbl9uYW1lIjoiUHJhamFrdGEiLCJpZHR5cCI6InVzZXIiLCJpcGFkZHIiOiIyNjAxOjI4MDo1ZjAwOmM3MDA6ZjUyMDoyZWMzOjJhYzI6ZTBiYSIsIm5hbWUiOiJQcmFqYWt0YSBLaW5pIiwib2lkIjoiYzU2M2ZhOTUtZDZlZi00NTU2LWEzYmUtYjM0NGM5N2FmMzUyIiwib25wcmVtX3NpZCI6IlMtMS01LTIxLTEyNzUyMTAwNzEtNDkyODk0MjIzLTY4MjAwMzMzMC0xMjE2NDEzIiwicGxhdGYiOiI1IiwicHVpZCI6IjEwMDMyMDAzNkIyM0Y5QzAiLCJyaCI6IjEuQVRZQUc0dnRQUTBIS1VhQzVNQ3dHZlJnVndNQUFBQUFBQUFBd0FBQUFBQUFBQUEyQUpBMkFBLiIsInNjcCI6IkZpbGVzLlJlYWQgRmlsZXMuUmVhZC5BbGwgRmlsZXMuUmVhZFdyaXRlIEZpbGVzLlJlYWRXcml0ZS5BbGwgU2l0ZXMuUmVhZC5BbGwgcHJvZmlsZSBvcGVuaWQgZW1haWwiLCJzaWduaW5fc3RhdGUiOlsia21zaSJdLCJzdWIiOiJvV2NxQTdYTUhVSUJlTlJ6YldEbVJwVEk4clRiVjk4aklQRmoyWlV3ZVNZIiwidGVuYW50X3JlZ2lvbl9zY29wZSI6Ik5BIiwidGlkIjoiM2RlZDhiMWItMDcwZC00NjI5LTgyZTQtYzBiMDE5ZjQ2MDU3IiwidW5pcXVlX25hbWUiOiJwcmtpODExMkBjb2xvcmFkby5lZHUiLCJ1cG4iOiJwcmtpODExMkBjb2xvcmFkby5lZHUiLCJ1dGkiOiJvYXBDcTFXZldVdXJORTJqdThOZkFRIiwidmVyIjoiMS4wIiwid2lkcyI6WyJiNzlmYmY0ZC0zZWY5LTQ2ODktODE0My03NmIxOTRlODU1MDkiXSwieG1zX2lkcmVsIjoiMTYgMSIsInhtc19zdCI6eyJzdWIiOiJQbGZxM3BzVXBRb2FFREhydXBwRmd2TTJzZldRbzdYdnJrSElRYzZQV1RjIn0sInhtc190Y2R0IjoxMzc4NDgwNjI4fQ.ukbMG_P5eoJ52N3AQaQOVxSYN8IU5JedwP_rFv2Zk3sTtCvflGNuSVzamexlhbnPyEEqsEY0fwAfi2DNl05vitwWpGsmwHI_aURTDiJNJlNH9CrjXY3oEWjsz2-iP5cA3bBBADy858w5cccxhNAnKOxMZO0tjvvzwfMGc12rXd_KtvunZ4OK3ALozHk-FZkLYuXQhBiREr2gvLRxCkugLcGHF6im70Srxyo3HkPfEfNtG118QabwVZ_i7bClXypo4wuXF7nz8aTFBoGdmpSei17UeB1nS3cy1QXZ6rTiSTCiRAweeaZZ_7qABZip4xabqakTm-0VyUYT-kihcAL6hQ\",\"token_type\":\"Bearer\",\"refresh_token\":\"1.ATYAG4vtPQ0HKUaC5MCwGfRgV9llVrGm7ZJAhTkO7Ddq_Vk2AJA2AA.AgABAwEAAADW6jl31mB3T7ugrWTT8pFeAwDs_wUA9P8lIJM1pzW0DYf1xFioBNEkvncpngERnF08_g0ogPAd0_i2n8F0a6-VphzCyXLW2o3z3blZdgloY_kSN0tlQxwPBcgdFhN-sdKc7x4jwkeocZ50o1lNaNQ8Q4fZcyLXCojud-A6Dtq0Vk32VH87cKFF9cXvCFCYj6_liT2V4zoRqJKBL4d-R9c-LBRcE3VUWOPa2C4FcPfZVH8q9MjyrKUc12dW8jEkfb47wtncMrWpJGgrg43F_oC4A3kaBKbLa4J4ix6AkOVcVYUykLJ0iHYmeNKdUSjT_lipavDGKe9tAvB_mZmBkf6fjKVaJh77VI-ipu4_zvPKX1P4_va-tVfEyBkntfweJls1qhd80E1nUAeoaJqHy5PX9q0wJNHG1o0AzEEhlvFhFcqk8VJJlFOJmt82Z_kRPYZcBmAZ5M5mlMZVhYHu9i57onqlP6gDUCiRTniWTjA6oBszzuwb-W-RGHGZp2hfmUaHc-TnbIuaVMvfW3bVaRbt14I9OGBB2i9HWBqIx7t8I7f_7xcdvuYH8A4yzDYxIO5rzqGgEIt-esP0NYS0tDwgLC0zWQ_KIpv7Xgx6c1RYxtsMs6D6FSgHFXqS-QPJg7W0kY7hcfspq-Ipvx-GmnyRdjqOisdPso7ASDSkIbvZQpZZVy5EHlA8bNFOOB8QYAHgwFS-AjdfUiKKw0aphtNG1ZMqLe4h52Bb5etOOEQpIdWHKzOlLQbMtUJb4A81dNG5y3rYLvyuw-L7D3Mm5UfMddJqRe7Flw6c\",\"expiry\":\"2024-12-06T02:35:50.212527-07:00\"}\n",
      "Choose a number from below, or type in an existing value\n",
      "\u001B[91m 1 / OneDrive Personal or Business\n",
      "   \\ \"onedrive\"\n",
      "\u001B[0m\u001B[92m 2 / Root Sharepoint site\n",
      "   \\ \"sharepoint\"\n",
      "\u001B[0m\u001B[91m 3 / Type in driveID\n",
      "   \\ \"driveid\"\n",
      "\u001B[0m\u001B[92m 4 / Type in SiteID\n",
      "   \\ \"siteid\"\n",
      "\u001B[0m\u001B[91m 5 / Search a Sharepoint site\n",
      "   \\ \"search\"\n",
      "\u001B[0mYour choice> 1\n",
      "Found 1 drives, please select the one you want to use:\n",
      "0: OneDrive (business) id=b!vRmi81-nAkiiTK6wJxzk1PyD0IjVCZ5BuJfCJ3Mft99aALHP0NT1RIzW0ul8WBwq\n",
      "Chose drive to use:> 0\n",
      "Found drive 'root' of type 'business', URL: https://o365coloradoedu-my.sharepoint.com/personal/prki8112_colorado_edu/Documents\n",
      "Is that okay?\n",
      "y) Yes\n",
      "n) No\n",
      "y/n> y\n",
      "--------------------\n",
      "[onedrive]\n",
      "type = onedrive\n",
      "token = {\"access_token\":\"eyJ0eXAiOiJKV1QiLCJub25jZSI6ImJJN21TU2VJNW1vNmIwZXBpdVo3dGlDcWdYd2RfQ0xFc1lva2h0QXZBaUkiLCJhbGciOiJSUzI1NiIsIng1dCI6Inp4ZWcyV09OcFRrd041R21lWWN1VGR0QzZKMCIsImtpZCI6Inp4ZWcyV09OcFRrd041R21lWWN1VGR0QzZKMCJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTAwMDAtYzAwMC0wMDAwMDAwMDAwMDAiLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC8zZGVkOGIxYi0wNzBkLTQ2MjktODJlNC1jMGIwMTlmNDYwNTcvIiwiaWF0IjoxNzMzNDczMjM0LCJuYmYiOjE3MzM0NzMyMzQsImV4cCI6MTczMzQ3Nzc0OSwiYWNjdCI6MCwiYWNyIjoiMSIsImFjcnMiOlsidXJuOnVzZXI6cmVnaXN0ZXJzZWN1cml0eWluZm8iXSwiYWlvIjoiQVRRQXkvOFlBQUFBWnBWVkR6azNZUnF1VUxTYVJacjVzMXVOTnc4dTFxU0xDeUpNTDRhRW1Zd3dtZ2hOemxpd2tWVDN5N3gwUmV5bSIsImFtciI6WyJwd2QiXSwiYXBwX2Rpc3BsYXluYW1lIjoicmNsb25lIiwiYXBwaWQiOiJiMTU2NjVkOS1lZGE2LTQwOTItODUzOS0wZWVjMzc2YWZkNTkiLCJhcHBpZGFjciI6IjEiLCJmYW1pbHlfbmFtZSI6IktpbmkiLCJnaXZlbl9uYW1lIjoiUHJhamFrdGEiLCJpZHR5cCI6InVzZXIiLCJpcGFkZHIiOiIyNjAxOjI4MDo1ZjAwOmM3MDA6ZjUyMDoyZWMzOjJhYzI6ZTBiYSIsIm5hbWUiOiJQcmFqYWt0YSBLaW5pIiwib2lkIjoiYzU2M2ZhOTUtZDZlZi00NTU2LWEzYmUtYjM0NGM5N2FmMzUyIiwib25wcmVtX3NpZCI6IlMtMS01LTIxLTEyNzUyMTAwNzEtNDkyODk0MjIzLTY4MjAwMzMzMC0xMjE2NDEzIiwicGxhdGYiOiI1IiwicHVpZCI6IjEwMDMyMDAzNkIyM0Y5QzAiLCJyaCI6IjEuQVRZQUc0dnRQUTBIS1VhQzVNQ3dHZlJnVndNQUFBQUFBQUFBd0FBQUFBQUFBQUEyQUpBMkFBLiIsInNjcCI6IkZpbGVzLlJlYWQgRmlsZXMuUmVhZC5BbGwgRmlsZXMuUmVhZFdyaXRlIEZpbGVzLlJlYWRXcml0ZS5BbGwgU2l0ZXMuUmVhZC5BbGwgcHJvZmlsZSBvcGVuaWQgZW1haWwiLCJzaWduaW5fc3RhdGUiOlsia21zaSJdLCJzdWIiOiJvV2NxQTdYTUhVSUJlTlJ6YldEbVJwVEk4clRiVjk4aklQRmoyWlV3ZVNZIiwidGVuYW50X3JlZ2lvbl9zY29wZSI6Ik5BIiwidGlkIjoiM2RlZDhiMWItMDcwZC00NjI5LTgyZTQtYzBiMDE5ZjQ2MDU3IiwidW5pcXVlX25hbWUiOiJwcmtpODExMkBjb2xvcmFkby5lZHUiLCJ1cG4iOiJwcmtpODExMkBjb2xvcmFkby5lZHUiLCJ1dGkiOiJvYXBDcTFXZldVdXJORTJqdThOZkFRIiwidmVyIjoiMS4wIiwid2lkcyI6WyJiNzlmYmY0ZC0zZWY5LTQ2ODktODE0My03NmIxOTRlODU1MDkiXSwieG1zX2lkcmVsIjoiMTYgMSIsInhtc19zdCI6eyJzdWIiOiJQbGZxM3BzVXBRb2FFREhydXBwRmd2TTJzZldRbzdYdnJrSElRYzZQV1RjIn0sInhtc190Y2R0IjoxMzc4NDgwNjI4fQ.ukbMG_P5eoJ52N3AQaQOVxSYN8IU5JedwP_rFv2Zk3sTtCvflGNuSVzamexlhbnPyEEqsEY0fwAfi2DNl05vitwWpGsmwHI_aURTDiJNJlNH9CrjXY3oEWjsz2-iP5cA3bBBADy858w5cccxhNAnKOxMZO0tjvvzwfMGc12rXd_KtvunZ4OK3ALozHk-FZkLYuXQhBiREr2gvLRxCkugLcGHF6im70Srxyo3HkPfEfNtG118QabwVZ_i7bClXypo4wuXF7nz8aTFBoGdmpSei17UeB1nS3cy1QXZ6rTiSTCiRAweeaZZ_7qABZip4xabqakTm-0VyUYT-kihcAL6hQ\",\"token_type\":\"Bearer\",\"refresh_token\":\"1.ATYAG4vtPQ0HKUaC5MCwGfRgV9llVrGm7ZJAhTkO7Ddq_Vk2AJA2AA.AgABAwEAAADW6jl31mB3T7ugrWTT8pFeAwDs_wUA9P8lIJM1pzW0DYf1xFioBNEkvncpngERnF08_g0ogPAd0_i2n8F0a6-VphzCyXLW2o3z3blZdgloY_kSN0tlQxwPBcgdFhN-sdKc7x4jwkeocZ50o1lNaNQ8Q4fZcyLXCojud-A6Dtq0Vk32VH87cKFF9cXvCFCYj6_liT2V4zoRqJKBL4d-R9c-LBRcE3VUWOPa2C4FcPfZVH8q9MjyrKUc12dW8jEkfb47wtncMrWpJGgrg43F_oC4A3kaBKbLa4J4ix6AkOVcVYUykLJ0iHYmeNKdUSjT_lipavDGKe9tAvB_mZmBkf6fjKVaJh77VI-ipu4_zvPKX1P4_va-tVfEyBkntfweJls1qhd80E1nUAeoaJqHy5PX9q0wJNHG1o0AzEEhlvFhFcqk8VJJlFOJmt82Z_kRPYZcBmAZ5M5mlMZVhYHu9i57onqlP6gDUCiRTniWTjA6oBszzuwb-W-RGHGZp2hfmUaHc-TnbIuaVMvfW3bVaRbt14I9OGBB2i9HWBqIx7t8I7f_7xcdvuYH8A4yzDYxIO5rzqGgEIt-esP0NYS0tDwgLC0zWQ_KIpv7Xgx6c1RYxtsMs6D6FSgHFXqS-QPJg7W0kY7hcfspq-Ipvx-GmnyRdjqOisdPso7ASDSkIbvZQpZZVy5EHlA8bNFOOB8QYAHgwFS-AjdfUiKKw0aphtNG1ZMqLe4h52Bb5etOOEQpIdWHKzOlLQbMtUJb4A81dNG5y3rYLvyuw-L7D3Mm5UfMddJqRe7Flw6c\",\"expiry\":\"2024-12-06T02:35:50.212527-07:00\"}\n",
      "drive_id = b!vRmi81-nAkiiTK6wJxzk1PyD0IjVCZ5BuJfCJ3Mft99aALHP0NT1RIzW0ul8WBwq\n",
      "drive_type = business\n",
      "--------------------\n",
      "y) Yes this is OK\n",
      "e) Edit this remote\n",
      "d) Delete this remote\n",
      "y/e/d> y\n",
      "Current remotes:\n",
      "\n",
      "Name                 Type\n",
      "====                 ====\n",
      "onedrive             onedrive\n",
      "\n",
      "e) Edit existing remote\n",
      "n) New remote\n",
      "d) Delete remote\n",
      "r) Rename remote\n",
      "c) Copy remote\n",
      "s) Set configuration password\n",
      "q) Quit config\n",
      "e/n/d/r/c/s/q> q\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!sudo mkdir /content/onedrive\n",
    "!nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShK9Cl36y-Tk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733473667010,
     "user_tz": 420,
     "elapsed": 283,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "fd40bb48-8426-4d48-96ee-960752d62316"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nohup: appending output to 'nohup.out'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/onedrive"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlF4dFFUzBtB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733473668268,
     "user_tz": 420,
     "elapsed": 2,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "e4bf354a-31d7-4e8e-a46b-30ad005a4490"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/onedrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connect to drive and import libraries\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "HrkBZkpD9pNi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8TQa7DC9gT_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481335409,
     "user_tz": 420,
     "elapsed": 29657,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "eb3a25bd-9d4e-435b-fc4a-7d7915066d6e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "os.chdir('/content/drive/MyDrive/Fairness_NLP/')"
   ],
   "metadata": {
    "id": "gvUTV-g-9mWR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481348849,
     "user_tz": 420,
     "elapsed": 1278,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def extract_text(input_string):\n",
    "  # Check if the input is a string\n",
    "    if not isinstance(input_string, str):\n",
    "        print(input_string)\n",
    "        raise ValueError(\"Expected a string input\")\n",
    "    # Use regex to find all text within parentheses and remove the text itself\n",
    "    matches = re.findall(r'\\((.*?)\\)', input_string)\n",
    "\n",
    "    if not matches:\n",
    "        return input_string\n",
    "\n",
    "    # Join the extracted texts with a space and return them\n",
    "    return ' '.join(matches)\n",
    "\n",
    "# Below helper function creates question-answer pairs (without filtering)\n",
    "def create_question_answer_pairs(interview):\n",
    "    question_answer_pairs = []\n",
    "    current_question = []\n",
    "    current_response = []\n",
    "\n",
    "    for index, row in interview.iterrows():\n",
    "        row['value'] = extract_text(str(row['value']))\n",
    "        if row['speaker'] == \"Ellie\":\n",
    "            # If there's an existing question and response, store the pair\n",
    "            if current_question and current_response:\n",
    "\n",
    "                question_answer_pairs.append({\n",
    "                    'question': \" \".join(current_question),\n",
    "                    'answer': \". \".join(current_response)\n",
    "                })\n",
    "                current_response = []  # Reset responses for the next question\n",
    "                current_question = []  # Reset question for the next batch\n",
    "\n",
    "            # Add the new question or follow-up from Ellie to the current question\n",
    "            current_question.append(str(row['value']))\n",
    "\n",
    "        elif row['speaker'] == \"Participant\" and current_question:\n",
    "            current_response.append(str(row['value']))\n",
    "\n",
    "    # Add the last question-answer pair if it exists\n",
    "    if current_question and current_response:\n",
    "\n",
    "        question_answer_pairs.append({\n",
    "            'question': \" \".join(current_question),\n",
    "            'answer': \". \".join(current_response)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(question_answer_pairs, columns=['question', 'answer'])"
   ],
   "metadata": {
    "id": "CnlE7fK-9w1z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481350418,
     "user_tz": 420,
     "elapsed": 2,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to create chunks of QA pairs with overlaps\n",
    "def chunk_qa_pairs(df, max_tokens=80, max_overlap_tokens=40):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_chunk_word_count = 0\n",
    "\n",
    "    # Combine questions and answers\n",
    "    qa_pairs = [f\"Interviewer: {row['question']} Interviewee: {row['answer']}\" for _, row in df.iterrows()]\n",
    "\n",
    "    for pair in qa_pairs:\n",
    "        # Count words in the current pair\n",
    "        pair_word_count = len(pair.split())\n",
    "\n",
    "        # Check if adding this pair exceeds the max tokens\n",
    "        if current_chunk_word_count + pair_word_count > max_tokens:\n",
    "            # Save the current chunk\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "            # Prepare for the next chunk\n",
    "            # Determine overlap (complete QA pairs)\n",
    "            overlap = []\n",
    "            overlap_word_count = 0\n",
    "\n",
    "            # Start from the last added complete pairs until it hits the token limit\n",
    "            for qa in reversed(current_chunk):\n",
    "                overlap_word_count += len(qa.split())\n",
    "                if overlap_word_count >= max_overlap_tokens:\n",
    "                    break\n",
    "                overlap.append(qa)\n",
    "\n",
    "            # Reverse to maintain original order\n",
    "            overlap.reverse()\n",
    "\n",
    "            # Start new chunk with overlap\n",
    "            current_chunk = overlap\n",
    "            current_chunk_word_count = sum(len(q.split()) for q in current_chunk)\n",
    "\n",
    "        # Add the current pair to the chunk\n",
    "        current_chunk.append(pair)\n",
    "        current_chunk_word_count += pair_word_count\n",
    "\n",
    "    # Add the last chunk if it has content\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n"
   ],
   "metadata": {
    "id": "6aDI-l0l-A2B",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481352538,
     "user_tz": 420,
     "elapsed": 2,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install openpyxl"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBe_AHrx-8ES",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1732179926311,
     "user_tz": 420,
     "elapsed": 3654,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "839931e2-09e5-4fab-a939-43ac6cec1c01"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create dictionary of {participant_id : PHQ_Binary}\n",
    "id_depression_label_map = {}\n",
    "all_ids = set()\n",
    "sheet_name = 'Metadata_mapping'\n",
    "file_path = 'DAIC demographc data.xlsx'\n",
    "data_csv = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "for i in range(len(data_csv['Participant_ID'])):\n",
    "    id_depression_label_map[data_csv['Participant_ID'][i]] = data_csv['PHQ_Binary'][i]\n",
    "    all_ids.add(data_csv['Participant_ID'][i])\n"
   ],
   "metadata": {
    "id": "2R4aJY-e-GL8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481357005,
     "user_tz": 420,
     "elapsed": 2219,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open('/content/drive/MyDrive/Fairness_NLP/RULE_BASED/adjective_embeddings.pkl', 'rb') as file:\n",
    "    true_dict = pickle.load(file)"
   ],
   "metadata": {
    "id": "8ecKYYA2U_8Z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481358495,
     "user_tz": 420,
     "elapsed": 1491,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install spacy\n",
    "import spacy"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMd89luAit_h",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481412602,
     "user_tz": 420,
     "elapsed": 21069,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "c7437fbe-85e8-4e05-f6bf-832688ff5c54"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.14.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to find adjectives in a sentence using spaCy\n",
    "def extract_adjectives_spacy(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    adjectives = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
    "    return adjectives"
   ],
   "metadata": {
    "id": "5e5dhUA6XMBf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733481416399,
     "user_tz": 420,
     "elapsed": 3801,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_rule_based_prediction(chunk, parameters, max_len):\n",
    "  adj_count = 0\n",
    "  adj_depressed = 0\n",
    "\n",
    "  adjectives = extract_adjectives_spacy(chunk)\n",
    "  if not adjectives:\n",
    "      return 0\n",
    "\n",
    "  encoded_text = tokenizer(chunk, return_tensors='pt', max_length=max_len, truncation=True, padding='max_length').to(device)\n",
    "\n",
    "  # Get embeddings from the model\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**encoded_text)\n",
    "\n",
    "  for adj in adjectives:\n",
    "      # Find the index of each adjective in the tokenized context\n",
    "      adj_tokens = tokenizer.tokenize(adj)\n",
    "      adj_token_id = tokenizer.convert_tokens_to_ids(adj_tokens[0])  # ID of the first token of the adjective\n",
    "      adj_index = (encoded_text.input_ids[0] == adj_token_id).nonzero(as_tuple=True)[0]  # Find position of token in input\n",
    "\n",
    "      if len(adj_index) > 0:  # Ensure adjective token was found\n",
    "          adj_embedding = outputs.last_hidden_state[0, adj_index[0], :].cpu().numpy()\n",
    "\n",
    "          if adj in true_dict:\n",
    "              adj_count+=1\n",
    "              true_embedding = true_dict[adj]\n",
    "              similarity = cosine_similarity([adj_embedding], [true_embedding])[0][0]\n",
    "\n",
    "              if similarity > parameters[0]:\n",
    "                adj_depressed+=1\n",
    "\n",
    "  try:\n",
    "    if (adj_depressed/adj_count) > parameters[1]:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  except Exception as exp:\n",
    "      return 0\n"
   ],
   "metadata": {
    "id": "pLaJOQfeWR0j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733482223111,
     "user_tz": 420,
     "elapsed": 3085,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "access_token = \"TOKEN\"\n",
    "model_name = \"mental/mental-roberta-base\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "model = AutoModel.from_pretrained(model_name, token=access_token).to(device)\n",
    "\n",
    "\n",
    "max_len = 510\n",
    "parameters = [0.75, 0.50]\n",
    "\n",
    "def collect_train_test_data(directory):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    attention_masks = []\n",
    "    rule_predictions = [] # collect rule based predictions\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "      if filename.endswith(\".csv\"):\n",
    "        interview_id = re.findall(r'\\d+', filename)[0]\n",
    "        print(interview_id)\n",
    "\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path, delimiter='\\t')\n",
    "        df.drop(columns=['start_time', 'stop_time'], axis=1, inplace=True)\n",
    "        df.fillna('', inplace=True)\n",
    "\n",
    "        # Step 1: Create QA Pair\n",
    "        qa_df = create_question_answer_pairs(df)\n",
    "        chunks = chunk_qa_pairs(qa_df, max_tokens=300, max_overlap_tokens=80)\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            encoded_text = tokenizer(chunk, add_special_tokens=True, max_length=max_len, truncation=True, padding=\"max_length\")\n",
    "            input_ids = encoded_text['input_ids']\n",
    "            attention_mask = encoded_text['attention_mask']\n",
    "            rule_prediction = get_rule_based_prediction(chunk, parameters, max_len)\n",
    "\n",
    "            # Convert to torch tensors and add to the lists\n",
    "            input_ids_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
    "            attention_mask_tensor = torch.tensor(attention_mask, dtype=torch.long)\n",
    "            label_tensor = torch.tensor(id_depression_label_map[int(interview_id)], dtype=torch.long)\n",
    "            rule_prediction_tensor = torch.tensor(rule_prediction, dtype=torch.long)\n",
    "\n",
    "            X_train.append(input_ids_tensor)\n",
    "            attention_masks.append(attention_mask_tensor)\n",
    "            Y_train.append(label_tensor)\n",
    "            rule_predictions.append(rule_prediction_tensor)\n",
    "\n",
    "    X_train = torch.stack(X_train)\n",
    "    Y_train = torch.stack(Y_train)\n",
    "    attention_masks = torch.stack(attention_masks)\n",
    "    rule_predictions = torch.stack(rule_predictions)\n",
    "    return X_train, Y_train, attention_masks, rule_predictions\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "Ga4n0aUp-xz4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733482225605,
     "user_tz": 420,
     "elapsed": 2495,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "780e06a9-8e2d-4d46-e889-de57c6830995"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the data\n",
    "directory = '/content/drive/MyDrive/Fairness_NLP/Dataset'\n",
    "X_train, Y_train, attention_masks, rule_predictions = collect_train_test_data(directory)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INqrSjhI-woW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733482424026,
     "user_tz": 420,
     "elapsed": 198423,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "e8c8a687-9f35-489a-863c-6aa2760c9a4e"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "345\n",
      "305\n",
      "309\n",
      "306\n",
      "341\n",
      "372\n",
      "364\n",
      "356\n",
      "369\n",
      "381\n",
      "360\n",
      "379\n",
      "350\n",
      "338\n",
      "362\n",
      "352\n",
      "335\n",
      "304\n",
      "339\n",
      "300\n",
      "331\n",
      "358\n",
      "329\n",
      "333\n",
      "355\n",
      "371\n",
      "319\n",
      "346\n",
      "344\n",
      "367\n",
      "316\n",
      "337\n",
      "328\n",
      "314\n",
      "324\n",
      "383\n",
      "302\n",
      "326\n",
      "349\n",
      "353\n",
      "327\n",
      "340\n",
      "365\n",
      "370\n",
      "301\n",
      "378\n",
      "347\n",
      "336\n",
      "334\n",
      "307\n",
      "325\n",
      "373\n",
      "308\n",
      "323\n",
      "343\n",
      "363\n",
      "366\n",
      "320\n",
      "354\n",
      "315\n",
      "310\n",
      "322\n",
      "357\n",
      "312\n",
      "311\n",
      "351\n",
      "303\n",
      "359\n",
      "361\n",
      "318\n",
      "313\n",
      "317\n",
      "332\n",
      "321\n",
      "330\n",
      "368\n",
      "348\n",
      "384\n",
      "416\n",
      "425\n",
      "374\n",
      "466\n",
      "475\n",
      "465\n",
      "485\n",
      "472\n",
      "422\n",
      "387\n",
      "426\n",
      "471\n",
      "392\n",
      "396\n",
      "476\n",
      "479\n",
      "447\n",
      "440\n",
      "415\n",
      "431\n",
      "424\n",
      "487\n",
      "488\n",
      "432\n",
      "437\n",
      "409\n",
      "454\n",
      "382\n",
      "412\n",
      "397\n",
      "492\n",
      "399\n",
      "433\n",
      "385\n",
      "450\n",
      "441\n",
      "491\n",
      "478\n",
      "436\n",
      "453\n",
      "449\n",
      "484\n",
      "400\n",
      "411\n",
      "467\n",
      "375\n",
      "446\n",
      "410\n",
      "413\n",
      "469\n",
      "395\n",
      "404\n",
      "443\n",
      "489\n",
      "388\n",
      "463\n",
      "434\n",
      "391\n",
      "470\n",
      "457\n",
      "429\n",
      "452\n",
      "464\n",
      "448\n",
      "389\n",
      "386\n",
      "390\n",
      "402\n",
      "407\n",
      "468\n",
      "481\n",
      "423\n",
      "439\n",
      "393\n",
      "490\n",
      "474\n",
      "486\n",
      "376\n",
      "403\n",
      "459\n",
      "418\n",
      "417\n",
      "405\n",
      "483\n",
      "401\n",
      "428\n",
      "456\n",
      "461\n",
      "435\n",
      "427\n",
      "406\n",
      "421\n",
      "377\n",
      "482\n",
      "473\n",
      "408\n",
      "455\n",
      "477\n",
      "420\n",
      "380\n",
      "430\n",
      "414\n",
      "419\n",
      "438\n",
      "445\n",
      "442\n",
      "462\n",
      "444\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(attention_masks.shape)\n",
    "print(rule_predictions.shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHvbC60lCtRm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733482426360,
     "user_tz": 420,
     "elapsed": 1033,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "a2ea11c6-b6fb-495f-d8ee-6bc1f1058279"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1780, 510])\n",
      "torch.Size([1780])\n",
      "torch.Size([1780, 510])\n",
      "torch.Size([1780])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import RobertaTokenizer, Trainer, TrainingArguments, AutoModel\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, balanced_accuracy_score\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "access_token = \"TOKEN\"\n",
    "\n",
    "# Custom model class\n",
    "class NeuroSymbolicClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, lambda_weight=0.1):\n",
    "        super(NeuroSymbolicClassifier, self).__init__()\n",
    "        self.base_model = AutoModel.from_pretrained(model_name, token=access_token)\n",
    "        self.classifier = nn.Linear(self.base_model.config.hidden_size, num_labels)\n",
    "        self.lambda_weight = lambda_weight  # Weight for rule-based penalty\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, rule_predictions=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Use the pooled output (e.g., CLS token) for classification\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        # Calculate neural loss (cross-entropy loss)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            neural_loss = loss_fn(logits, labels)\n",
    "\n",
    "            # Calculate rule-based penalty if rule_predictions are provided\n",
    "            if rule_predictions is not None:\n",
    "                rule_penalty = torch.mean((torch.argmax(logits, dim=1) != rule_predictions).float())\n",
    "                total_loss = neural_loss + self.lambda_weight * rule_penalty\n",
    "            else:\n",
    "                total_loss = neural_loss\n",
    "\n",
    "            loss = total_loss\n",
    "\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "\n",
    "# Define a custom Dataset class\n",
    "class DepressionDataset(Dataset):\n",
    "    def __init__(self, input_ids, labels, attention_masks, rule_predictions):\n",
    "        self.input_ids = input_ids\n",
    "        self.labels = labels\n",
    "        self.attention_masks = attention_masks\n",
    "        self.rule_predictions = rule_predictions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long).squeeze(),\n",
    "            'rule_predictions': torch.tensor(self.rule_predictions[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Define the compute_metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    bac = balanced_accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'balanced_accuracy': bac\n",
    "    }\n",
    "\n",
    "# Initialize KFold and metrics storage\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=17)\n",
    "k_fold_iteration = 0\n",
    "total_bac = []\n",
    "total_precision = []\n",
    "total_recall = []\n",
    "total_f1 = []\n",
    "\n",
    "trained_models_base_dir = '/content/drive/MyDrive/Fairness_NLP//Neurosymbolic_Classifier_5thDec'\n",
    "model_name = \"mental/mental-roberta-base\"\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    k_fold_iteration += 1\n",
    "\n",
    "    # Split into training and validation sets for this fold\n",
    "    train_inputs, val_inputs = X_train[train_index], X_train[test_index]\n",
    "    train_labels, val_labels = Y_train[train_index], Y_train[test_index]\n",
    "    attention_mask_train, attention_mask_val = attention_masks[train_index], attention_masks[test_index]\n",
    "    rule_preds_train, rule_preds_val = rule_predictions[train_index], rule_predictions[test_index]\n",
    "\n",
    "    # Initialize datasets for the current fold\n",
    "    train_dataset = DepressionDataset(train_inputs, train_labels, attention_mask_train, rule_preds_train)\n",
    "    val_dataset = DepressionDataset(val_inputs, val_labels, attention_mask_val, rule_preds_val)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = NeuroSymbolicClassifier(model_name, num_labels=2, lambda_weight=0.1)\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'{trained_models_base_dir}/trained_models/k_fold_{k_fold_iteration}/',\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=4,\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy='epoch',\n",
    "        logging_dir=f'{trained_models_base_dir}/logs/k_fold_{k_fold_iteration}',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    "        save_total_limit=1,\n",
    "        logging_steps=1\n",
    "    )\n",
    "\n",
    "    # Create a Trainer for this fold\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model on the validation set and store metrics\n",
    "    metrics = trainer.evaluate(val_dataset)\n",
    "    total_bac.append(metrics['eval_balanced_accuracy'])\n",
    "    total_precision.append(metrics['eval_precision'])\n",
    "    total_recall.append(metrics['eval_recall'])\n",
    "    total_f1.append(metrics['eval_f1'])\n",
    "\n",
    "    print(f\"Fold {k_fold_iteration} - Balanced Accuracy: {metrics['eval_balanced_accuracy']}, Precision: {metrics['eval_precision']}, Recall: {metrics['eval_recall']}, F1 Score: {metrics['eval_f1']}\")\n",
    "\n",
    "# Print overall results after cross-validation\n",
    "print(f\"Average Balanced Accuracy: {np.mean(total_bac)}, Average Precision: {np.mean(total_precision)}, Average Recall: {np.mean(total_recall)}, Average F1 Score: {np.mean(total_f1)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hICx8tvH-WEp",
    "outputId": "42639e97-6716-4735-9157-3979ba14c5bb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733490561808,
     "user_tz": 420,
     "elapsed": 8108349,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1780' max='1780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1780/1780 27:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>0.499553</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.502319</td>\n",
       "      <td>0.744382</td>\n",
       "      <td>0.473988</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.674190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.429956</td>\n",
       "      <td>0.817416</td>\n",
       "      <td>0.532374</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.738764</td>\n",
       "      <td>0.513089</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.710514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.058800</td>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.783708</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.483516</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.713964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.332835</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.728580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.701722</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.721487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>1.499435</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.717846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.959134</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.432203</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.725800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>1.759866</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.462264</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.730017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:10]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 1 - Balanced Accuracy: 0.700354609929078, Precision: 0.5692307692307692, Recall: 0.5, F1 Score: 0.5323741007194245\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1780' max='1780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1780/1780 26:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.498893</td>\n",
       "      <td>0.783708</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.534551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>0.529741</td>\n",
       "      <td>0.733146</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.587359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.443545</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.645869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.782137</td>\n",
       "      <td>0.766854</td>\n",
       "      <td>0.551351</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.738212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.846089</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.753402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>1.332050</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.552764</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.747508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>1.449664</td>\n",
       "      <td>0.772472</td>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.746741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.152080</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.739458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.360435</td>\n",
       "      <td>0.800562</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.739553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.332742</td>\n",
       "      <td>0.806180</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.738116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:10]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 2 - Balanced Accuracy: 0.739457542649032, Precision: 0.6268656716417911, Recall: 0.5675675675675675, F1 Score: 0.5957446808510638\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1780' max='1780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1780/1780 26:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.523679</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.541255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.114600</td>\n",
       "      <td>0.505066</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.621544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.355100</td>\n",
       "      <td>0.479581</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.695936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.596043</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.648079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.332900</td>\n",
       "      <td>1.006679</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.734308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>1.229240</td>\n",
       "      <td>0.794944</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.708777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.601189</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.712515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>1.587937</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.718925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.668914</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.718925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>1.598060</td>\n",
       "      <td>0.789326</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.720613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:10]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 3 - Balanced Accuracy: 0.6480793060718711, Precision: 0.7435897435897436, Recall: 0.3333333333333333, F1 Score: 0.4603174603174603\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1780' max='1780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1780/1780 26:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.371700</td>\n",
       "      <td>0.459780</td>\n",
       "      <td>0.794944</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.506757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.761300</td>\n",
       "      <td>0.482360</td>\n",
       "      <td>0.794944</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.736007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.394479</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.749090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.760789</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.771229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.761381</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.782538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>1.100653</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.784071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.879763</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.778225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.942750</td>\n",
       "      <td>0.862360</td>\n",
       "      <td>0.652482</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.773577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>1.286137</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.796483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.153870</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.786851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:10]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 4 - Balanced Accuracy: 0.7735767682576193, Precision: 0.6865671641791045, Recall: 0.6216216216216216, F1 Score: 0.6524822695035462\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at mental/mental-roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1780' max='1780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1780/1780 27:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315800</td>\n",
       "      <td>0.513777</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174600</td>\n",
       "      <td>0.516218</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.564130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.553339</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.630707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.665488</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.670652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.834198</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.678714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>1.195717</td>\n",
       "      <td>0.783708</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.705163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>1.358002</td>\n",
       "      <td>0.772472</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.671286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.609200</td>\n",
       "      <td>1.448234</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.694475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.597403</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.700543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>1.600947</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.721105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:10]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 5 - Balanced Accuracy: 0.6787137681159421, Precision: 0.5606060606060606, Recall: 0.4625, F1 Score: 0.5068493150684932\n",
      "Average Balanced Accuracy: 0.7080363990047085, Average Precision: 0.6373718818494938, Average Recall: 0.4970045045045045, Average F1 Score: 0.5495535652919976\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Average Balanced Accuracy: {np.mean(total_bac)}, Average Precision: {np.mean(total_precision)}, Average Recall: {np.mean(total_recall)}, Average F1 Score: {np.mean(total_f1)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "n8XdrFJu5mKy",
    "executionInfo": {
     "status": "error",
     "timestamp": 1730517839820,
     "user_tz": 360,
     "elapsed": 164,
     "user": {
      "displayName": "Prajakta Kini",
      "userId": "14771910641565599211"
     }
    },
    "outputId": "2e1748bd-a4af-482b-a675-f283a6d3493a",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'total_bac' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-c7713e348670>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Average Balanced Accuracy: {np.mean(total_bac)}, Average Precision: {np.mean(total_precision)}, Average Recall: {np.mean(total_recall)}, Average F1 Score: {np.mean(total_f1)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'total_bac' is not defined"
     ]
    }
   ]
  }
 ]
}
